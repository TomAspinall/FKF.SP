% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fkf.SP.R
\name{fkf.SP}
\alias{fkf.SP}
\title{Fast Kalman Filtering using Sequential Processing.}
\usage{
fkf.SP(a0, P0, dt, ct, Tt, Zt, HHt, GGt, yt)
}
\arguments{
\item{a0}{A \code{vector} giving the initial value/estimation of the state variable}

\item{P0}{A \code{matrix} giving the variance of a0}

\item{dt}{A \code{matrix} giving the intercept of the transition equation}

\item{ct}{A \code{matrix} giving the intercept of the measaurement equation}

\item{Tt}{An \code{array} giving factor of the transition equation}

\item{Zt}{An \code{array} giving the factor of the measurement equation}

\item{HHt}{An \code{array} giving the variance of the innovations of the transition equation}

\item{GGt}{A \code{vector} giving the diagonal elements of the \code{matrix} for the variance of the disturbances of the measurement equation. Covariance between disturbances
is not supported under the Sequential Processing method.}

\item{yt}{A \code{matrix} containing the observations. "NA"- values are allowed}
}
\value{
A \code{numeric} value corresponding to the log-likelihood calculated by the Kalman Filter. Ideal for maximum likelihood estimation through optimization routines such as \code{optim}.

\bold{fkf and fkf.SP values}:

Outputs of the \code{fkf} and \code{fkf.SP} functions differ slightly in that \code{fkf} returns a list object of filtered values returned by the
algorithm, whereas \code{fkf.SP} returns only a \code{numeric} value corresponding to the log-likelihood returned by the filter. \code{fkf}
is thus appropriate when filtered values are required and \code{fkf.SP} is appropriate for parameter estimation through maximum likelihood
methods.

When there are no missing observations (ie. "NA" values) in \code{matrix} yt, the return of function \code{fkf.SP} and the \code{logLik}
object returned within the list of function \code{fkf} are identical. When there are NA values, however, the log-likelihood score returned
by \code{fkf.SP} is always higher. The log-likelihood score of the \code{FKF} C code is instantiated through the calculation of
\mjeqn{- n \times d \times log(2\pi)}{ASCII representation}, where \mjeqn{n}{ASCII representation} is the number of columns of \code{matrix}
\code{yt} and \mjeqn{d}{ASCII representation} is the number of rows of \code{matrix} \code{yt}. Under the assumption that there are
missing observations, \mjeqn{d}{ASCII representation} would instead become \mjeqn{d_t}{ASCII representation}, where \mjeqn{d_t \leq d \forall t}{ASCII representation}.
Whilst this doesn't influence parameter estimation, because observation matrix \code{yt} and thus the offset resulting from this is kept constant during maximum likelihood estimation,
this does result in low bias of the log-likelihood scores output by the \code{fkf} function.
}
\description{
\loadmathjax
The \code{fkf.SP} function performs fast and flexible Kalman Filtering using Sequential Processing. It is designed for efficient parameter
estimation through maximum likelihood estimation. \code{fkf.SP} wraps the C-function \code{fkf_SP} which relies upon the linear algebra subroutines of BLAS.
Sequential Processing is a univariate treatment of a multivariate series of observations and can benefit from computational efficiencies over
traditional Kalman Filtering. \code{fkf.SP} is based from the \code{fkf} function of the \code{FKF} package but, in general, is a faster Kalman Filtering method.
fkf.SP is compatible with missing observations.
}
\details{
\bold{Parameters}:

The \code{fkf.SP} function builds upon the \code{fkf} function of the \code{FKF} package by adjusting the Kalman Filtering algorithm to
utilize sequential processing. The \code{fkf.SP} and \code{fkf} functions feature highly similar
arguments for compatibility purposes; only argument \code{GGt} has changed from an \code{array} type object to a \code{vector} or \code{matrix} type object.
The \code{fkf.SP} function takes the additional assumption over the \code{fkf} function that the variance of the disturbances of the measurement
equation are independent; a requirement of sequential processing (see below).

The parameters can either be constant or deterministic
time-varying. Assume the number of discrete time observations is \mjeqn{n}{n}
i.e. \mjeqn{y = y_t}{y = y_t} where \mjeqn{t = 1, \cdots, n}{t = 1, \cdots, n}. Let \mjeqn{m}{m} be the
dimension of the state variable and \mjeqn{d}{ASCII representation} the dimension of the observations. Then, the parameters admit the following
classes and dimensions:

\tabular{ll}{
\code{dt} \tab either a \mjeqn{m \times n}{m * n} (time-varying) or a \mjeqn{m \times 1}{m * 1} (constant) matrix. \cr
\code{Tt} \tab either a \mjeqn{m \times m \times n}{m * m * n} or a \mjeqn{m \times m \times 1}{m * m * 1} array. \cr
\code{HHt} \tab either a \mjeqn{m \times m \times n}{m * m * n} or a \mjeqn{m \times m \times 1}{m * m * 1} array. \cr
\code{ct} \tab either a \mjeqn{d \times n}{d * n} or a \mjeqn{d \times 1}{d * 1} matrix. \cr
\code{Zt} \tab either a \mjeqn{d \times m \times n}{d * m * n} or a \mjeqn{d \times m \times 1}{d * m * 1} array. \cr
\code{GGt} \tab either a \mjeqn{d \times n}{d * n} (time-varying) or a \mjeqn{d \times 1}{d * 1} matrix. \cr
\code{yt} \tab a \mjeqn{d \times n}{d * n} matrix.
}

\bold{State Space Form}

The following notation follows that of Koopman \emph{et al.} (1999) and the documentation of the \code{fkf} function. The Kalman Filter is characterised by the transition and measurement equations:

\mjdeqn{\alpha_{t + 1} = d_t + T_t \cdot \alpha_t + H_t \cdot \eta_t}{alpha(t + 1) = d(t) + T(t) alpha(t) + H(t) * eta(t)}
\mjdeqn{y_t = c_t + Z_t \cdot \alpha_t + G_t \cdot \epsilon_t}{y(t) = c(t) + Z(t) alpha(t) + G(t) * epsilon(t)}

where \mjeqn{\eta_t}{eta(t)} and \mjeqn{\epsilon_t}{epsilon(t)} are iid
\mjeqn{N(0, I_m)}{N(0, I(m))} and iid \mjeqn{N(0, I_d)}{N(0, I(d))},
respectively, and \mjeqn{\alpha_t}{alpha(t)} denotes the state
vector. The parameters admit the following dimensions:

\tabular{lll}{
\mjeqn{a_t \in R^m}{a\link{t} \in R^m} \tab \mjeqn{d_t \in R^m}{d\link{t} \in R^m} \tab \mjeqn{\eta_t \in R^m}{eta\link{t} \in R^m} \cr
\mjeqn{T_t \in R^{m \times m}}{T\link{t} \in R^(m * m )} \tab \mjeqn{H_t \in R^{m \times m}}{H\link{t}
\in R^(m * m)} \tab \cr
\mjeqn{y_t \in R^d}{y\link{t} in R^d} \tab \mjeqn{c_t \in R^d}{c\link{t} \in R^d} \tab \mjeqn{\epsilon_t \in R^d}{epsilon\link{t} \in R^d} \cr
\mjeqn{Z_t \in R^{d \times m}}{Z\link{t} \in R^(d * m)} \tab \mjeqn{G_t \in R^{d \times d}}{G\link{t}
\in R^(d * d)} \tab
}

Note that \code{fkf.SP} takes as input \code{HHt} and \code{GGt} which corresponds to \mjeqn{H_t H_t'}{H\link{t} * t(H\link{t})} and
\mjeqn{diag(G_t)^2}{diag(G\link{t})^2} respectively.

\bold{Sequential Processing Iteration}:

Traditional Kalman Filtering takes the entire observational vector \mjeqn{y_t}{y\link{t}} as the items for analysis. Sequential Processing
is an alternate approach that filters the elements of \mjeqn{y_t}{y\link{t}} one at a time. Let \mjeqn{p}{p} equal the number of observations
at time \mjeqn{t}{t} (ie. when considering possible missing observations \mjeqn{p \leq {d}}{p <= d}) . This univariate treatment of the multivariate series
has the advantage that the function of the covariance matrix, \mjeqn{F_t}{F\link{t}}, becomes \mjeqn{1 \times 1}{1 * 1}, avoiding the inversion of
a \mjeqn{p \times p}{p * p} matrix. This can provide computational efficiencies (especially under the case of many observations, ie. \mjeqn{p}{p} is large)

The SP iteration involves treating the vector series: \mjeqn{y_1,\cdots,y_n}{y_1,\cdots,y_n} instead as the scalar series
\mjeqn{y_{1,1},\cdots,y_{(1,p)},y_{2,1},\cdots,y_{(n,p_n)}}{y_{1,1},\cdots,y_{(1,p)},y_{2,1},\cdots,y_{(n,p_n )}}

For any time point, the observation vector is given by:

\mjdeqn{y_t'=(y_{(t,1)},\cdots,y_{(t,p)} )}{y_t'=(y_(t,1),\cdots,y_(t,p) )}

The filtering equations are written as:

\mjdeqn{a_{t,i+1} = a_{t,i} + K_{t,i} v_{t,i}}{A}
\mjdeqn{P_{t,i+1} = P_{t,i} - K_{t,i} F_{t,i} K_{t,i}'}{A}
Where:
\mjdeqn{\hat y_{t,i} = c_t + Z_t \cdot a_{t,i}}{^y_t = c\link{t} + Z\link{t} * a_\link{t,i}}
\mjdeqn{v_{t,i}=y_{t,i}-\hat y_{t,i}}{A}
\mjdeqn{F_{t,i} = Z_{t,i} P_{t,i} Z_{t,i}'+ GGt_{t,i}}{GGt\link{t,i}}
\mjdeqn{K_{t,i} = P_{t,i} Z_{t,i}' F_{t,i}^{-1}}{A}
\mjdeqn{i = 1, \cdots, p}{i = 1, ..., p}

Transition from time \mjeqn{t}{t} to \mjeqn{t+1}{t+1} occurs through the standard transition equations.

\mjdeqn{\alpha_{t + 1,1} = d_t + T_t \cdot \alpha_{t,p}}{alpha(t + 1,1) = d(t) + T(t) alpha(t,p)}

\mjdeqn{P_{t + 1,1} = T_t \cdot P_{t,p} \cdot T_t' + HHt}{P(t + 1,1) = T(t) P(t,p) T(t)' + H(t)}

The log-likelihood at time \mjeqn{t}{t} is given by:

\mjdeqn{log L_t = -\frac{p}{2}log(2\pi) - \frac{1}{2}\sum_{i=1}^p(log F_i + \frac{v_i^2}{F_i})}{log L_t = -p/2 * log(2 * pi) - 1/2 * sum_{i=1}^p (log F_i + (v_i^2)/F_i)}

Where the log-likelihood of observations is:

\mjdeqn{log L = \sum_t^n{log L_t}}{log L = \sum_t^n{log L_t}}

There's several distinctions between the Multivariate Kalman Filter and the Sequential processing filtered values.
The elements of the innovation vector \mjeqn{v_t}{v_t} are not the same as \mjeqn{v_{t,i}}{v\link{t,i}} for \mjeqn{i=1,\cdots,p}{i=1,\cdots,p}.
This is also true of the diagonal elements of the variance matrix \mjeqn{F_t}{F_t} and the variances \mjeqn{F_{t,i}}{F_{t,i}}, for \mjeqn{i=1,\cdots,p}{i=1,\cdots,p};
only the first diagonal element of \mjeqn{F_t}{F_t} is equal to \mjeqn{F_{t,1}}{F\link{t,1}}.
}
\examples{

##The following examples follow those presented within the fkf function,
##performing computational timing comparisons between the fkf and fkf.SP functions.

## <-------------------------------------------------------------------------------
##Example 1 - ARMA(2,1) model estimation.
## <-------------------------------------------------------------------------------

n <- 1000

## Set the AR parameters

ar1 <- 0.6
ar2 <- 0.2
ma1 <- -0.2
sigma <- sqrt(0.2)

## Sample from an ARMA(2, 1) process
a <- arima.sim(model = list(ar = c(ar1, ar2), ma = ma1), n = n,
            innov = rnorm(n) * sigma)

## Create a state space representation out of the four ARMA parameters
arma21ss <- function(ar1, ar2, ma1, sigma) {
Tt <- matrix(c(ar1, ar2, 1, 0), ncol = 2)
Zt <- matrix(c(1, 0), ncol = 2)
ct <- matrix(0)
dt <- matrix(0, nrow = 2)
GGt <- matrix(0)
H <- matrix(c(1, ma1), nrow = 2) * sigma
HHt <- H \%*\% t(H)
a0 <- c(0, 0)
P0 <- matrix(1e6, nrow = 2, ncol = 2)
return(list(a0 = a0, P0 = P0, ct = ct, dt = dt, Zt = Zt, Tt = Tt, GGt = GGt,
            HHt = HHt))
            }

## The objective function passed to 'optim'
objective <- function(theta, yt, SP = F) {
sp <- arma21ss(theta["ar1"], theta["ar2"], theta["ma1"], theta["sigma"])
if(SP){
 ans <- fkf.SP(a0 = sp$a0, P0 = sp$P0, dt = sp$dt, ct = sp$ct, Tt = sp$Tt,
               Zt = sp$Zt, HHt = sp$HHt, GGt = sp$GGt, yt = yt)
 return(-ans)
 }
 else{
 ans <- fkf(a0 = sp$a0, P0 = sp$P0, dt = sp$dt, ct = sp$ct, Tt = sp$Tt,
            Zt = sp$Zt, HHt = sp$HHt, GGt = sp$GGt, yt = yt)
 return(-ans$logLik)
 }
}

###FKF Package:
set.seed(1)
start = Sys.time()
theta <- c(ar = c(0, 0), ma1 = 0, sigma = 1)
fit <- optim(theta, objective, yt = rbind(a), hessian = TRUE, SP = F)
FKF_runtime = Sys.time() - start

###fkf.SP Package:
set.seed(1)
start = Sys.time()
theta <- c(ar = c(0, 0), ma1 = 0, sigma = 1)
fit <- optim(theta, objective, yt = rbind(a), hessian = TRUE, SP = T)
fkf.SP_runtime = Sys.time() - start

sp <- arma21ss(fit$par["ar1"], fit$par["ar2"], fit$par["ma1"], fit$par["sigma"])

##Speed Comparison - ARMA(2,1) process (100 iterations):
set.seed(1)
start = Sys.time()
for(i in 1:1e3) fkf(a0 = sp$a0, P0 = sp$P0, dt = sp$dt, ct = sp$ct, Tt = sp$Tt,
                   Zt = sp$Zt, HHt = sp$HHt, GGt = sp$GGt, yt = rbind(a))
run.time_FKF = Sys.time() - start

start = Sys.time()
set.seed(1)
for(i in 1:1e3) fkf.SP(a0 = sp$a0, P0 = sp$P0, dt = sp$dt, ct = sp$ct, Tt = sp$Tt,
                      Zt = sp$Zt, HHt = sp$HHt, GGt = sp$GGt, yt = rbind(a))
run.time_fkf.SP = Sys.time() - start

##Print Output:
print(c(FKF = run.time_FKF, fkf.SP = run.time_fkf.SP))

## <-------------------------------------------------------------------------------
#Example 2 - Nile Example:
## <-------------------------------------------------------------------------------
#Local level model for the Nile's annual flow:

## Transition equation:
## alpha[t+1] = alpha[t] + eta[t], eta[t] ~ N(0, HHt)
## Measurement equation:
## y[t] = alpha[t] + eps[t], eps[t] ~  N(0, GGt)


y <- Nile

## Set parameters:
dt <- ct <- matrix(0)
Zt <- Tt <- matrix(1)
a0 <- y[1]            # Estimation of the first year flow
P0 <- matrix(100)     # Variance of 'a0'
HHt <- GGt <- var(y, na.rm = TRUE) * .5

##Speed Comparison - Nile Data (10,000 iterations):
set.seed(1)
start = Sys.time()
for(i in 1:1e4) fkf(a0, P0, dt, ct, Tt, Zt, HHt = matrix(fit.fkf$par[1]),
                   GGt = matrix(fit.fkf$par[2]), yt = rbind(y))
run.time_FKF = Sys.time() - start

set.seed(1)
start = Sys.time()
for(i in 1:1e4) fkf.SP(a0, P0, dt, ct, Tt, Zt, HHt = matrix(fit.fkf$par[1]),
                      GGt = matrix(fit.fkf$par[2]), yt = rbind(y))
run.time_fkf.SP = Sys.time() - start

print(c(FKF = run.time_FKF, fkf.SP = run.time_fkf.SP))


}
\references{
Anderson, B. D. O. and Moore. J. B. (1979). \emph{Optimal Filtering} Englewood Cliffs: Prentice-Hall.

Fahrmeir, L. and tutz, G. (1994) \emph{Multivariate Statistical Modelling Based on Generalized Linear Models.} Berlin: Springer.

Koopman, S. J., Shephard, N., Doornik, J. A. (1999). Statistical algorithms for models in state space using SsfPack 2.2. \emph{Econometrics Journal}, Royal Economic Society, vol. 2(1), pages 107-160.

Durbin, James, and Siem Jan Koopman (2012). \emph{Time series analysis by state space methods.} Oxford university press.

David Luethi, Philipp Erb and Simon Otziger (2018). FKF: Fast Kalman Filter. R package version 0.1.5.
https://CRAN.R-project.org/package=FKF
}
